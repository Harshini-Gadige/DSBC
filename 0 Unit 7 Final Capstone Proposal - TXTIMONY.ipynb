{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Civilians are collateral damage at best and deliberate targets at worst in violent conflicts between state and non-state political actors globally. \n",
    "\n",
    "The systematic censorship or outright suppression of domestic and interational journalism creates accountability and information vacuums that sustain social oblivion beyond regional or national borders. This in turn emboldens the most horrifically inhumane inclinations of both factions. \n",
    "\n",
    "The resulting escalation cycle only tends to be disrupted or at least exposed when important economic interests are meaningfully impacted that the political powers concerned actively or passively intervene. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TXTIMONY is the concept for a text-powered crisis monitoring model that predicts incident cause based on real-time civilian reports, diminishing reliance on journalistic coverage and the news cycle. It would run on the Ushahidi platform, which was created in 2008 to crowdsource and map data post-election violence in Kenya and has since become an enterprise data collection, management, and visualization solution for citizen engagement, election monitoring, humanitarian aid, incident management, and international development organizations.  \n",
    "\n",
    "Force-multiplying the immense agency of courageous civilians who digitally document their accounts of political violence and then circumvent internet and mobile messaging service disruptions to disseminate them is crucial for two reasons: \n",
    "- It would enable non-governmental humanitarian assistance organizations to continuously re-assess developments and microtarget operations. \n",
    "- It would anonymize and democratize news production such that real-time reporting is accelerated and attribution-based retaliation is impossible.\n",
    "\n",
    "The use cases I'm focusing on are:\n",
    "- Cameroonian armed forces' violent conflicts with the Ambazonian Separatist Movement.\n",
    "- Nigerian armed forces' violent conflicts with the Boko Haram Insurgency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anticipated Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**The Project** \n",
    "\n",
    "- Dynamic Data's Inaccessiblity: Ideally, I'd be assembling my text corpus from mobile messages or social media posts. My ability to demonstrate the product's utility is constrained by how static my data sources are.  \n",
    "- Methodology: I've framed incident cause identification as an extraction problem, but it may actually be an abstraction problem. I'd like to try building a neural network classifier for incident cause prediction. Both implementations may be beyond the scope of my current skillset. \n",
    "\n",
    "\n",
    "**The Product** \n",
    "\n",
    "- Data Veracity: Identifying and filtering out duplicative reports and deliberate disinformation would need to be a priority. Applying Artificial Intelligence to combatting the latter is still a nascent effort - a startup called [Factmata](http://factmata.com/) is currently tackling this challenge.  \n",
    "- Digital Censorship: The ability to circumvent web and mobile network blocks would pose an accessibility challenge. Chinese college students have devised a novel approach that might also be applicable in this context - embedding messages in [Blockchain](https://slate.com/technology/2018/07/blockchain-is-helping-to-circumvent-censorship-in-china.html) transaction descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Armed Conflict Location & Event Data (ACLED) project  is one of the most credible free and open providers of real-time data  for analyzing and visualizing political violence in the developing world. It's primarily powered by reports from domestic and international news outlets, supplemented by local sources who tend to cover farther-flung locations.  \n",
    "\n",
    "Based on API query results, I've identified an arbitrary subset of reputable non-government-owned domestic and international news outlets whose sites I intend to scrape for articles on the movement in Cameroon and the insurgency in Nigeria with which I'll create my text corpus:\n",
    "\n",
    "**Domestic News Outlets**\n",
    "- Cameroon Intelligence Report (Cameroon)\n",
    "- Journal du Cameroun (Cameroon)\n",
    "- The Guardian (Nigeria)\n",
    "- Vanguard (Nigeria)\n",
    "\n",
    "**International News Outlets**\n",
    "- Agence France-Presse (France)\n",
    "- British Broadcasting Corporation (United Kingdom)\n",
    "- Reuters (United Kingdom)\n",
    "- Voice of America (United States)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source Selection: ACLED API Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've already made arbitrary data source selections.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site Scraping & Text Corpus Creation: Beautiful Soup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I intend to find URLs for all articles pertaining to either crises on outlets' sites and reading their raw text into a dump file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Step 1: Preprocessing: SKLearn & GenSim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next I intend to parse the raw text, calculate a TF-IDF matrix, generate the word list, define a target number of topics, link words to the topics, and then extract top words with their loadings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "## Pipeline Step 2: Topic Extraction: pLSA, LDA, & NNMF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I intend to fit these models to the text corpus and compare the results, with a focus on examining topic distinctions/overlap and  sparsity. I anticipate issues with locally optimal solutions and overfitting (with pLSA in particular), but I'd ideally like to see some semblance of consistency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "source": [
    "## Pipeline Step 3: Predictive Classification: Neural Network & Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally I intend to train these models to predict incident cause for each of the articles comprising the text corpus and test the model's efficacy in the wild by feeding it news articles it hasn't seen. Cross-validation and hyperparameter tuning will be built into this step.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
